# StatQuest机器学习系列 - 决策树和分类树详解

1. 决策树和分类树的区别是什么？
决策树是一种通过一系列判断来做出决策的工具。
- 分类树：将数据分类到不同类别的决策树
- 回归树：用于预测数值的决策树
- 两者的主要区别在于输出类型：类别vs数值

2. 决策树的基本结构包含哪些组成部分？
决策树由三种主要节点类型组成：
- 根节点：树的最顶部，是决策的起点
- 内部节点：有进出箭头的中间节点，代表判断条件
- 叶节点：只有进入箭头的终端节点，代表最终决策结果

3. 如何理解节点的"纯度"概念？
纯度反映了节点中样本类别的一致性程度：
- 高纯度：节点中大多数样本属于同一类别
- 低纯度：节点中样本类别较为混杂
- 目标是通过分裂得到纯度更高的子节点

4. 基尼不纯度如何计算及应用？
基尼不纯度计算方法：
- 公式：1 - Σ(pi²)，其中pi是类别i的概率
- 值域：[0,1]，0表示完全纯净，1表示最不纯
- 应用：选择能使子节点基尼不纯度最小的特征进行分裂

5. 如何处理不同类型的特征数据？
特征处理方式因数据类型而异：
- 类别型数据：直接根据不同类别值进行分裂
- 数值型数据：
  - 首先对数据排序
  - 计算相邻值的平均值作为候选分割点
  - 选择使基尼不纯度最小的分割点

6. 决策树如何预测新数据？
预测过程遵循简单的路径追踪：
- 从根节点开始
- 根据节点的判断条件选择分支
- 沿着分支一直到达叶节点
- 叶节点的主导类别即为预测结果

7. 什么是过拟合，如何避免？
过拟合表现及解决方案：
- 表现：模型过度拟合训练数据，泛化能力差
- 解决方法：
  - 剪枝：移除不必要的节点
  - 设置约束：限制树的深度和叶节点最小样本数
  - 使用交叉验证选择最佳参数

8. 如何评估决策树模型的性能？
性能评估方法：
- 交叉验证：将数据分成多份，轮流作为验证集
- 评估指标：
  - 分类准确率
  - 混淆矩阵
  - 精确率和召回率
- 通过这些指标选择最优的模型参数

> 补充说明：决策树是一种直观且容易解释的模型，特别适合处理混合类型的特征数据。但要注意控制模型复杂度，防止过拟合问题。